{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z_UNMVV7Me72"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация текстов, encoder-decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Pv2YC_qMgEj"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 50\n",
    "latent_dim = 256\n",
    "num_samples = 10000\n",
    "data_path = 'rus.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lOt_n2jgMgQM"
   },
   "outputs": [],
   "source": [
    "# Собираем из текстов токены и делаем pne-hot вектора на каждый токен\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split('\\t')\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FyWZEVl3MgXn"
   },
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tzMpYi_pMgcC"
   },
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6STbwxL2MgT8"
   },
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
    "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "4Grq0tLmNmum",
    "outputId": "45993b5e-fe0a-4c15-e5be-d5fc6bd4679d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125/125 [==============================] - 2s 18ms/step - loss: 1.1376 - accuracy: 0.7728 - val_loss: 0.9363 - val_accuracy: 0.7552\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.7439 - accuracy: 0.7995 - val_loss: 0.7863 - val_accuracy: 0.7903\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.6972 - accuracy: 0.8179 - val_loss: 0.7397 - val_accuracy: 0.7958\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.6064 - accuracy: 0.8361 - val_loss: 0.6715 - val_accuracy: 0.8162\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.5625 - accuracy: 0.8439 - val_loss: 0.6356 - val_accuracy: 0.8212\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.5348 - accuracy: 0.8484 - val_loss: 0.6103 - val_accuracy: 0.8266\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.5158 - accuracy: 0.8528 - val_loss: 0.5919 - val_accuracy: 0.8308\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.4977 - accuracy: 0.8570 - val_loss: 0.5714 - val_accuracy: 0.8358\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.4827 - accuracy: 0.8606 - val_loss: 0.5583 - val_accuracy: 0.8383\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.4700 - accuracy: 0.8637 - val_loss: 0.5458 - val_accuracy: 0.8414\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.4585 - accuracy: 0.8664 - val_loss: 0.5349 - val_accuracy: 0.8446\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.4477 - accuracy: 0.8693 - val_loss: 0.5280 - val_accuracy: 0.8463\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.4375 - accuracy: 0.8725 - val_loss: 0.5172 - val_accuracy: 0.8490\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.4267 - accuracy: 0.8755 - val_loss: 0.5091 - val_accuracy: 0.8522\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.4178 - accuracy: 0.8777 - val_loss: 0.5003 - val_accuracy: 0.8549\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.4092 - accuracy: 0.8803 - val_loss: 0.4967 - val_accuracy: 0.8556\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.4007 - accuracy: 0.8830 - val_loss: 0.4882 - val_accuracy: 0.8585\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.3918 - accuracy: 0.8854 - val_loss: 0.4821 - val_accuracy: 0.8609\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.3842 - accuracy: 0.8878 - val_loss: 0.4774 - val_accuracy: 0.8616\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.3766 - accuracy: 0.8899 - val_loss: 0.4722 - val_accuracy: 0.8622\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.3685 - accuracy: 0.8919 - val_loss: 0.4670 - val_accuracy: 0.8654\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.3605 - accuracy: 0.8944 - val_loss: 0.4662 - val_accuracy: 0.8644\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.3535 - accuracy: 0.8965 - val_loss: 0.4582 - val_accuracy: 0.8685\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.3453 - accuracy: 0.8992 - val_loss: 0.4554 - val_accuracy: 0.8690\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.3383 - accuracy: 0.9009 - val_loss: 0.4492 - val_accuracy: 0.8714\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.3303 - accuracy: 0.9036 - val_loss: 0.4463 - val_accuracy: 0.8732\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.3243 - accuracy: 0.9052 - val_loss: 0.4461 - val_accuracy: 0.8732\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.3166 - accuracy: 0.9076 - val_loss: 0.4410 - val_accuracy: 0.8745\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.3100 - accuracy: 0.9090 - val_loss: 0.4393 - val_accuracy: 0.8748\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.3029 - accuracy: 0.9113 - val_loss: 0.4363 - val_accuracy: 0.8759\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.2953 - accuracy: 0.9136 - val_loss: 0.4321 - val_accuracy: 0.8777\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.2883 - accuracy: 0.9157 - val_loss: 0.4324 - val_accuracy: 0.8772\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.2815 - accuracy: 0.9174 - val_loss: 0.4295 - val_accuracy: 0.8783\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.2759 - accuracy: 0.9189 - val_loss: 0.4281 - val_accuracy: 0.8797\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.2683 - accuracy: 0.9213 - val_loss: 0.4288 - val_accuracy: 0.8796\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.2623 - accuracy: 0.9229 - val_loss: 0.4278 - val_accuracy: 0.8798\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.2555 - accuracy: 0.9249 - val_loss: 0.4292 - val_accuracy: 0.8806\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.2502 - accuracy: 0.9263 - val_loss: 0.4257 - val_accuracy: 0.8805\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.2434 - accuracy: 0.9281 - val_loss: 0.4247 - val_accuracy: 0.8820\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.2375 - accuracy: 0.9299 - val_loss: 0.4275 - val_accuracy: 0.8823\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.2308 - accuracy: 0.9316 - val_loss: 0.4260 - val_accuracy: 0.8829\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.2262 - accuracy: 0.9326 - val_loss: 0.4290 - val_accuracy: 0.8820\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.2194 - accuracy: 0.9350 - val_loss: 0.4263 - val_accuracy: 0.8840\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.2135 - accuracy: 0.9367 - val_loss: 0.4318 - val_accuracy: 0.8827\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.2077 - accuracy: 0.9385 - val_loss: 0.4334 - val_accuracy: 0.8831\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.2018 - accuracy: 0.9401 - val_loss: 0.4392 - val_accuracy: 0.8819\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.1969 - accuracy: 0.9416 - val_loss: 0.4328 - val_accuracy: 0.8838\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.1916 - accuracy: 0.9429 - val_loss: 0.4344 - val_accuracy: 0.8846\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.1860 - accuracy: 0.9448 - val_loss: 0.4366 - val_accuracy: 0.8848\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.1808 - accuracy: 0.9461 - val_loss: 0.4419 - val_accuracy: 0.8839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7cc9f60860>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 782
    },
    "colab_type": "code",
    "id": "gGZVlq56Ny65",
    "outputId": "5b98b65c-67e1-4561-df21-e1b35849ee6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: Shoot!\n",
      "Decoded sentence: Полежите!\n",
      "\n",
      "Input sentence: Wait.\n",
      "Decoded sentence: Подождите.\n",
      "\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Всём здоровье!\n",
      "\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Идите ужа.\n",
      "\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Идите ужа.\n",
      "\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: Постатавна!\n",
      "\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Я победил!\n",
      "\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Вот бы?\n",
      "\n",
      "Input sentence: Fire!\n",
      "Decoded sentence: Пожар!\n",
      "\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Вот бы?\n",
      "\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Бегите!\n",
      "\n",
      "Input sentence: Eat it.\n",
      "Decoded sentence: Пошу, протиля.\n",
      "\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Всём здоровье!\n",
      "\n",
      "Input sentence: Help!\n",
      "Decoded sentence: Помогите!\n",
      "\n",
      "Input sentence: Relax.\n",
      "Decoded sentence: Расслабьтесь.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "for seq_index in np.random.choice(range(100), 15, replace=False):\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7DjvOSU_Ny_v"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import tensorflow as tf\n",
    "data_path = 'rus.txt'\n",
    "num_samples = 10000\n",
    "\n",
    "#tf.enable_eager_execution()\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    w = re.sub(r\"[^a-zа-яA-ZА-Я?.!,¿]+\", \" \", w)\n",
    "    w = w.strip()\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w\n",
    "\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split('\\t')\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(preprocess_sentence(input_text))\n",
    "    target_texts.append(preprocess_sentence(target_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "82G-n0tPNzHt"
   },
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9CyEinreNm3b"
   },
   "outputs": [],
   "source": [
    "input_tensor, inp_lang_tokenizer = tokenize(input_texts)\n",
    "target_tensor, targ_lang_tokenizer = tokenize(target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WULUcayrNm_I"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "input_tensor_train, input_tensor_val, \\\n",
    " target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GIE8WGOqNnEZ"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "\n",
    "vocab_inp_size = len(inp_lang_tokenizer.word_index)+1\n",
    "vocab_tar_size = len(targ_lang_tokenizer.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cfPjOJ_YNm8w"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.lstm(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))\n",
    "\n",
    "    \n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights\n",
    "    \n",
    "    \n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state = self.lstm(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        x = self.fc(output)\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LYsXVlyvVXTg"
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H-ZVg24-VXi0"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        dec_hidden = enc_hidden\n",
    "        dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "    \n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "ZD9M5DLCVXgP",
    "outputId": "8ab80bec-42f1-4cb6-f7f5-c765226eb912"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 1.6407\n",
      "Epoch 2 Loss 1.2239\n",
      "Epoch 3 Loss 1.0469\n",
      "Epoch 4 Loss 0.9038\n",
      "Epoch 5 Loss 0.7755\n",
      "Epoch 6 Loss 0.6584\n",
      "Epoch 7 Loss 0.5503\n",
      "Epoch 8 Loss 0.4563\n",
      "Epoch 9 Loss 0.3754\n",
      "Epoch 10 Loss 0.3122\n",
      "Epoch 11 Loss 0.2652\n",
      "Epoch 12 Loss 0.2313\n",
      "Epoch 13 Loss 0.2072\n",
      "Epoch 14 Loss 0.1896\n",
      "Epoch 15 Loss 0.1785\n",
      "Epoch 16 Loss 0.1677\n",
      "Epoch 17 Loss 0.1628\n",
      "Epoch 18 Loss 0.1552\n",
      "Epoch 19 Loss 0.1484\n",
      "Epoch 20 Loss 0.1462\n",
      "Epoch 21 Loss 0.1423\n",
      "Epoch 22 Loss 0.1399\n",
      "Epoch 23 Loss 0.1368\n",
      "Epoch 24 Loss 0.1359\n",
      "Epoch 25 Loss 0.1323\n",
      "Epoch 26 Loss 0.1314\n",
      "Epoch 27 Loss 0.1319\n",
      "Epoch 28 Loss 0.1307\n",
      "Epoch 29 Loss 0.1279\n",
      "Epoch 30 Loss 0.1255\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "for epoch in range(EPOCHS):\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "    \n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7CqMBVfdVXa8"
   },
   "outputs": [],
   "source": [
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
    "\n",
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    result = ''\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "    return result, sentence, attention_plot\n",
    "\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    fontdict = {'fontsize': 14}\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    plt.show()\n",
    "    \n",
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 580
    },
    "colab_type": "code",
    "id": "ry7SxC-ZVqwP",
    "outputId": "4b0dd365-ee4f-439e-9e45-20e41783e85f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> good morning ! <end>\n",
      "Predicted translation: доброе ! <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'good morning!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kgAmGP_2VXP5"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead) \n",
    "  but it must be broadcastable for addition.\n",
    "  \n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "    \n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "    \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "  # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jumm3T13bpVj"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights\n",
    "    \n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xk6q3qkybpjV"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2\n",
    "    \n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    \n",
    "    def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(\n",
    "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2\n",
    "    \n",
    "    \n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                                self.d_model)\n",
    "\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # adding embedding and position encoding.\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "biqK_QQkbpuG"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                                 look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G8KQiiADb6y1"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                               input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                               target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i0IGLRf2cCVL"
   },
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = len(inp_lang_tokenizer.index_word) + 2\n",
    "target_vocab_size = len(targ_lang_tokenizer.index_word) + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AQfCWOrtcCd1"
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lhLH-sZDcCkf"
   },
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "  \n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7B5j1YcYcCif"
   },
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "  \n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LS8pQp2ecM_T"
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')\n",
    "\n",
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AAURw1PRcNIy"
   },
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sJ02TFRlcNNm"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "  \n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "  \n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar_inp, \n",
    "                                 True, \n",
    "                                 enc_padding_mask, \n",
    "                                 combined_mask, \n",
    "                                 dec_padding_mask)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "  \n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ViOsNIcTcb2q",
    "outputId": "cd783ae4-2d19-4aa1-d441-4adc5e7b06a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 8.4386 Accuracy 0.0000\n",
      "Epoch 1 Batch 50 Loss 8.2437 Accuracy 0.0240\n",
      "Epoch 1 Batch 100 Loss 8.0335 Accuracy 0.0572\n",
      "Epoch 1 Loss 7.9479 Accuracy 0.0637\n",
      "Epoch 2 Batch 0 Loss 7.5353 Accuracy 0.0909\n",
      "Epoch 2 Batch 50 Loss 7.3217 Accuracy 0.0921\n",
      "Epoch 2 Batch 100 Loss 7.0857 Accuracy 0.1214\n",
      "Epoch 2 Loss 6.9654 Accuracy 0.1339\n",
      "Epoch 3 Batch 0 Loss 6.3173 Accuracy 0.1918\n",
      "Epoch 3 Batch 50 Loss 6.0128 Accuracy 0.1901\n",
      "Epoch 3 Batch 100 Loss 5.7377 Accuracy 0.1899\n",
      "Epoch 3 Loss 5.6004 Accuracy 0.1901\n",
      "Epoch 4 Batch 0 Loss 4.8913 Accuracy 0.1861\n",
      "Epoch 4 Batch 50 Loss 4.5997 Accuracy 0.1973\n",
      "Epoch 4 Batch 100 Loss 4.4123 Accuracy 0.2011\n",
      "Epoch 4 Loss 4.3224 Accuracy 0.2025\n",
      "Epoch 5 Batch 0 Loss 3.7654 Accuracy 0.2244\n",
      "Epoch 5 Batch 50 Loss 3.7055 Accuracy 0.2142\n",
      "Epoch 5 Batch 100 Loss 3.6277 Accuracy 0.2181\n",
      "Epoch 5 Loss 3.5906 Accuracy 0.2194\n",
      "Epoch 6 Batch 0 Loss 3.2521 Accuracy 0.2344\n",
      "Epoch 6 Batch 50 Loss 3.2723 Accuracy 0.2291\n",
      "Epoch 6 Batch 100 Loss 3.2341 Accuracy 0.2299\n",
      "Epoch 6 Loss 3.2151 Accuracy 0.2306\n",
      "Epoch 7 Batch 0 Loss 3.1379 Accuracy 0.2301\n",
      "Epoch 7 Batch 50 Loss 3.0246 Accuracy 0.2358\n",
      "Epoch 7 Batch 100 Loss 2.9899 Accuracy 0.2364\n",
      "Epoch 7 Loss 2.9748 Accuracy 0.2370\n",
      "Epoch 8 Batch 0 Loss 2.9554 Accuracy 0.2259\n",
      "Epoch 8 Batch 50 Loss 2.7828 Accuracy 0.2429\n",
      "Epoch 8 Batch 100 Loss 2.7892 Accuracy 0.2431\n",
      "Epoch 8 Loss 2.7860 Accuracy 0.2429\n",
      "Epoch 9 Batch 0 Loss 2.5314 Accuracy 0.2557\n",
      "Epoch 9 Batch 50 Loss 2.6609 Accuracy 0.2450\n",
      "Epoch 9 Batch 100 Loss 2.6191 Accuracy 0.2468\n",
      "Epoch 9 Loss 2.6233 Accuracy 0.2472\n",
      "Epoch 10 Batch 0 Loss 2.5248 Accuracy 0.2543\n",
      "Epoch 10 Batch 50 Loss 2.4774 Accuracy 0.2504\n",
      "Epoch 10 Batch 100 Loss 2.4788 Accuracy 0.2506\n",
      "Epoch 10 Loss 2.4751 Accuracy 0.2511\n",
      "Epoch 11 Batch 0 Loss 2.4814 Accuracy 0.2401\n",
      "Epoch 11 Batch 50 Loss 2.3413 Accuracy 0.2556\n",
      "Epoch 11 Batch 100 Loss 2.3279 Accuracy 0.2561\n",
      "Epoch 11 Loss 2.3203 Accuracy 0.2564\n",
      "Epoch 12 Batch 0 Loss 2.1657 Accuracy 0.2656\n",
      "Epoch 12 Batch 50 Loss 2.1790 Accuracy 0.2624\n",
      "Epoch 12 Batch 100 Loss 2.1871 Accuracy 0.2606\n",
      "Epoch 12 Loss 2.1814 Accuracy 0.2611\n",
      "Epoch 13 Batch 0 Loss 1.9238 Accuracy 0.2628\n",
      "Epoch 13 Batch 50 Loss 2.0585 Accuracy 0.2634\n",
      "Epoch 13 Batch 100 Loss 2.0505 Accuracy 0.2650\n",
      "Epoch 13 Loss 2.0449 Accuracy 0.2653\n",
      "Epoch 14 Batch 0 Loss 2.0043 Accuracy 0.2571\n",
      "Epoch 14 Batch 50 Loss 1.8996 Accuracy 0.2699\n",
      "Epoch 14 Batch 100 Loss 1.9100 Accuracy 0.2696\n",
      "Epoch 14 Loss 1.9132 Accuracy 0.2700\n",
      "Epoch 15 Batch 0 Loss 1.6583 Accuracy 0.2884\n",
      "Epoch 15 Batch 50 Loss 1.7676 Accuracy 0.2763\n",
      "Epoch 15 Batch 100 Loss 1.7904 Accuracy 0.2751\n",
      "Epoch 15 Loss 1.7857 Accuracy 0.2751\n",
      "Epoch 16 Batch 0 Loss 1.7290 Accuracy 0.2784\n",
      "Epoch 16 Batch 50 Loss 1.6365 Accuracy 0.2829\n",
      "Epoch 16 Batch 100 Loss 1.6481 Accuracy 0.2814\n",
      "Epoch 16 Loss 1.6589 Accuracy 0.2807\n",
      "Epoch 17 Batch 0 Loss 1.4327 Accuracy 0.2969\n",
      "Epoch 17 Batch 50 Loss 1.5086 Accuracy 0.2890\n",
      "Epoch 17 Batch 100 Loss 1.5275 Accuracy 0.2872\n",
      "Epoch 17 Loss 1.5400 Accuracy 0.2863\n",
      "Epoch 18 Batch 0 Loss 1.3649 Accuracy 0.2926\n",
      "Epoch 18 Batch 50 Loss 1.3910 Accuracy 0.2942\n",
      "Epoch 18 Batch 100 Loss 1.4182 Accuracy 0.2913\n",
      "Epoch 18 Loss 1.4292 Accuracy 0.2907\n",
      "Epoch 19 Batch 0 Loss 1.1765 Accuracy 0.3153\n",
      "Epoch 19 Batch 50 Loss 1.2864 Accuracy 0.2981\n",
      "Epoch 19 Batch 100 Loss 1.3077 Accuracy 0.2967\n",
      "Epoch 19 Loss 1.3189 Accuracy 0.2962\n",
      "Epoch 20 Batch 0 Loss 1.1987 Accuracy 0.3082\n",
      "Epoch 20 Batch 50 Loss 1.1767 Accuracy 0.3051\n",
      "Epoch 20 Batch 100 Loss 1.1989 Accuracy 0.3019\n",
      "Epoch 20 Loss 1.2175 Accuracy 0.3009\n",
      "Epoch 21 Batch 0 Loss 1.1258 Accuracy 0.3210\n",
      "Epoch 21 Batch 50 Loss 1.0619 Accuracy 0.3140\n",
      "Epoch 21 Batch 100 Loss 1.0922 Accuracy 0.3092\n",
      "Epoch 21 Loss 1.1089 Accuracy 0.3074\n",
      "Epoch 22 Batch 0 Loss 1.0404 Accuracy 0.3168\n",
      "Epoch 22 Batch 50 Loss 0.9932 Accuracy 0.3150\n",
      "Epoch 22 Batch 100 Loss 1.0212 Accuracy 0.3117\n",
      "Epoch 22 Loss 1.0344 Accuracy 0.3102\n",
      "Epoch 23 Batch 0 Loss 0.8549 Accuracy 0.3196\n",
      "Epoch 23 Batch 50 Loss 0.9012 Accuracy 0.3206\n",
      "Epoch 23 Batch 100 Loss 0.9350 Accuracy 0.3165\n",
      "Epoch 23 Loss 0.9516 Accuracy 0.3152\n",
      "Epoch 24 Batch 0 Loss 0.7830 Accuracy 0.3352\n",
      "Epoch 24 Batch 50 Loss 0.8101 Accuracy 0.3265\n",
      "Epoch 24 Batch 100 Loss 0.8637 Accuracy 0.3198\n",
      "Epoch 24 Loss 0.8877 Accuracy 0.3186\n",
      "Epoch 25 Batch 0 Loss 0.7842 Accuracy 0.3395\n",
      "Epoch 25 Batch 50 Loss 0.7592 Accuracy 0.3302\n",
      "Epoch 25 Batch 100 Loss 0.8074 Accuracy 0.3238\n",
      "Epoch 25 Loss 0.8245 Accuracy 0.3225\n",
      "Epoch 26 Batch 0 Loss 0.6613 Accuracy 0.3509\n",
      "Epoch 26 Batch 50 Loss 0.7141 Accuracy 0.3329\n",
      "Epoch 26 Batch 100 Loss 0.7693 Accuracy 0.3267\n",
      "Epoch 26 Loss 0.7870 Accuracy 0.3251\n",
      "Epoch 27 Batch 0 Loss 0.5832 Accuracy 0.3466\n",
      "Epoch 27 Batch 50 Loss 0.6750 Accuracy 0.3357\n",
      "Epoch 27 Batch 100 Loss 0.7196 Accuracy 0.3298\n",
      "Epoch 27 Loss 0.7394 Accuracy 0.3276\n",
      "Epoch 28 Batch 0 Loss 0.5073 Accuracy 0.3523\n",
      "Epoch 28 Batch 50 Loss 0.6457 Accuracy 0.3368\n",
      "Epoch 28 Batch 100 Loss 0.6971 Accuracy 0.3316\n",
      "Epoch 28 Loss 0.7186 Accuracy 0.3295\n",
      "Epoch 29 Batch 0 Loss 0.5256 Accuracy 0.3452\n",
      "Epoch 29 Batch 50 Loss 0.6056 Accuracy 0.3392\n",
      "Epoch 29 Batch 100 Loss 0.6696 Accuracy 0.3317\n",
      "Epoch 29 Loss 0.6911 Accuracy 0.3299\n",
      "Epoch 30 Batch 0 Loss 0.6046 Accuracy 0.3338\n",
      "Epoch 30 Batch 50 Loss 0.5899 Accuracy 0.3398\n",
      "Epoch 30 Batch 100 Loss 0.6551 Accuracy 0.3346\n",
      "Epoch 30 Loss 0.6800 Accuracy 0.3319\n",
      "Epoch 31 Batch 0 Loss 0.5370 Accuracy 0.3366\n",
      "Epoch 31 Batch 50 Loss 0.5804 Accuracy 0.3411\n",
      "Epoch 31 Batch 100 Loss 0.6433 Accuracy 0.3337\n",
      "Epoch 31 Loss 0.6663 Accuracy 0.3317\n",
      "Epoch 32 Batch 0 Loss 0.5363 Accuracy 0.3253\n",
      "Epoch 32 Batch 50 Loss 0.5689 Accuracy 0.3421\n",
      "Epoch 32 Batch 100 Loss 0.6340 Accuracy 0.3351\n",
      "Epoch 32 Loss 0.6622 Accuracy 0.3324\n",
      "Epoch 33 Batch 0 Loss 0.4769 Accuracy 0.3480\n",
      "Epoch 33 Batch 50 Loss 0.5689 Accuracy 0.3410\n",
      "Epoch 33 Batch 100 Loss 0.6220 Accuracy 0.3358\n",
      "Epoch 33 Loss 0.6435 Accuracy 0.3338\n",
      "Epoch 34 Batch 0 Loss 0.5213 Accuracy 0.3537\n",
      "Epoch 34 Batch 50 Loss 0.5564 Accuracy 0.3427\n",
      "Epoch 34 Batch 100 Loss 0.6038 Accuracy 0.3382\n",
      "Epoch 34 Loss 0.6243 Accuracy 0.3364\n",
      "Epoch 35 Batch 0 Loss 0.5330 Accuracy 0.3423\n",
      "Epoch 35 Batch 50 Loss 0.5332 Accuracy 0.3434\n",
      "Epoch 35 Batch 100 Loss 0.5876 Accuracy 0.3385\n",
      "Epoch 35 Loss 0.6085 Accuracy 0.3371\n",
      "Epoch 36 Batch 0 Loss 0.4544 Accuracy 0.3580\n",
      "Epoch 36 Batch 50 Loss 0.5117 Accuracy 0.3479\n",
      "Epoch 36 Batch 100 Loss 0.5581 Accuracy 0.3423\n",
      "Epoch 36 Loss 0.5765 Accuracy 0.3409\n",
      "Epoch 37 Batch 0 Loss 0.4803 Accuracy 0.3636\n",
      "Epoch 37 Batch 50 Loss 0.5010 Accuracy 0.3475\n",
      "Epoch 37 Batch 100 Loss 0.5535 Accuracy 0.3429\n",
      "Epoch 37 Loss 0.5739 Accuracy 0.3408\n",
      "Epoch 38 Batch 0 Loss 0.4225 Accuracy 0.3452\n",
      "Epoch 38 Batch 50 Loss 0.4800 Accuracy 0.3496\n",
      "Epoch 38 Batch 100 Loss 0.5355 Accuracy 0.3442\n",
      "Epoch 38 Loss 0.5577 Accuracy 0.3418\n",
      "Epoch 39 Batch 0 Loss 0.4987 Accuracy 0.3537\n",
      "Epoch 39 Batch 50 Loss 0.4881 Accuracy 0.3491\n",
      "Epoch 39 Batch 100 Loss 0.5412 Accuracy 0.3439\n",
      "Epoch 39 Loss 0.5591 Accuracy 0.3420\n",
      "Epoch 40 Batch 0 Loss 0.4371 Accuracy 0.3608\n",
      "Epoch 40 Batch 50 Loss 0.4620 Accuracy 0.3495\n",
      "Epoch 40 Batch 100 Loss 0.5119 Accuracy 0.3467\n",
      "Epoch 40 Loss 0.5289 Accuracy 0.3449\n",
      "Epoch 41 Batch 0 Loss 0.4194 Accuracy 0.3423\n",
      "Epoch 41 Batch 50 Loss 0.4669 Accuracy 0.3503\n",
      "Epoch 41 Batch 100 Loss 0.5095 Accuracy 0.3465\n",
      "Epoch 41 Loss 0.5301 Accuracy 0.3447\n",
      "Epoch 42 Batch 0 Loss 0.3814 Accuracy 0.3636\n",
      "Epoch 42 Batch 50 Loss 0.4624 Accuracy 0.3491\n",
      "Epoch 42 Batch 100 Loss 0.5054 Accuracy 0.3453\n",
      "Epoch 42 Loss 0.5123 Accuracy 0.3455\n",
      "Epoch 43 Batch 0 Loss 0.3980 Accuracy 0.3693\n",
      "Epoch 43 Batch 50 Loss 0.4361 Accuracy 0.3550\n",
      "Epoch 43 Batch 100 Loss 0.4852 Accuracy 0.3491\n",
      "Epoch 43 Loss 0.5047 Accuracy 0.3475\n",
      "Epoch 44 Batch 0 Loss 0.3422 Accuracy 0.3736\n",
      "Epoch 44 Batch 50 Loss 0.4416 Accuracy 0.3552\n",
      "Epoch 44 Batch 100 Loss 0.4850 Accuracy 0.3489\n",
      "Epoch 44 Loss 0.5021 Accuracy 0.3469\n",
      "Epoch 45 Batch 0 Loss 0.4070 Accuracy 0.3281\n",
      "Epoch 45 Batch 50 Loss 0.4254 Accuracy 0.3523\n",
      "Epoch 45 Batch 100 Loss 0.4674 Accuracy 0.3498\n",
      "Epoch 45 Loss 0.4881 Accuracy 0.3479\n",
      "Epoch 46 Batch 0 Loss 0.3003 Accuracy 0.3594\n",
      "Epoch 46 Batch 50 Loss 0.4247 Accuracy 0.3549\n",
      "Epoch 46 Batch 100 Loss 0.4623 Accuracy 0.3517\n",
      "Epoch 46 Loss 0.4853 Accuracy 0.3486\n",
      "Epoch 47 Batch 0 Loss 0.3298 Accuracy 0.3722\n",
      "Epoch 47 Batch 50 Loss 0.4100 Accuracy 0.3563\n",
      "Epoch 47 Batch 100 Loss 0.4629 Accuracy 0.3510\n",
      "Epoch 47 Loss 0.4829 Accuracy 0.3488\n",
      "Epoch 48 Batch 0 Loss 0.2973 Accuracy 0.3722\n",
      "Epoch 48 Batch 50 Loss 0.4073 Accuracy 0.3540\n",
      "Epoch 48 Batch 100 Loss 0.4484 Accuracy 0.3517\n",
      "Epoch 48 Loss 0.4692 Accuracy 0.3497\n",
      "Epoch 49 Batch 0 Loss 0.3225 Accuracy 0.3750\n",
      "Epoch 49 Batch 50 Loss 0.3909 Accuracy 0.3593\n",
      "Epoch 49 Batch 100 Loss 0.4385 Accuracy 0.3534\n",
      "Epoch 49 Loss 0.4579 Accuracy 0.3510\n",
      "Epoch 50 Batch 0 Loss 0.2996 Accuracy 0.3764\n",
      "Epoch 50 Batch 50 Loss 0.3938 Accuracy 0.3569\n",
      "Epoch 50 Batch 100 Loss 0.4422 Accuracy 0.3527\n",
      "Epoch 50 Loss 0.4569 Accuracy 0.3516\n",
      "Epoch 51 Batch 0 Loss 0.3746 Accuracy 0.3480\n",
      "Epoch 51 Batch 50 Loss 0.3984 Accuracy 0.3562\n",
      "Epoch 51 Batch 100 Loss 0.4344 Accuracy 0.3537\n",
      "Epoch 51 Loss 0.4526 Accuracy 0.3512\n",
      "Epoch 52 Batch 0 Loss 0.3953 Accuracy 0.3423\n",
      "Epoch 52 Batch 50 Loss 0.3864 Accuracy 0.3560\n",
      "Epoch 52 Batch 100 Loss 0.4307 Accuracy 0.3528\n",
      "Epoch 52 Loss 0.4481 Accuracy 0.3514\n",
      "Epoch 53 Batch 0 Loss 0.3596 Accuracy 0.3764\n",
      "Epoch 53 Batch 50 Loss 0.3826 Accuracy 0.3584\n",
      "Epoch 53 Batch 100 Loss 0.4237 Accuracy 0.3545\n",
      "Epoch 53 Loss 0.4416 Accuracy 0.3527\n",
      "Epoch 54 Batch 0 Loss 0.3998 Accuracy 0.3480\n",
      "Epoch 54 Batch 50 Loss 0.3876 Accuracy 0.3583\n",
      "Epoch 54 Batch 100 Loss 0.4226 Accuracy 0.3545\n",
      "Epoch 54 Loss 0.4431 Accuracy 0.3528\n",
      "Epoch 55 Batch 0 Loss 0.4162 Accuracy 0.3636\n",
      "Epoch 55 Batch 50 Loss 0.3856 Accuracy 0.3582\n",
      "Epoch 55 Batch 100 Loss 0.4227 Accuracy 0.3544\n",
      "Epoch 55 Loss 0.4394 Accuracy 0.3528\n",
      "Epoch 56 Batch 0 Loss 0.3057 Accuracy 0.3707\n",
      "Epoch 56 Batch 50 Loss 0.3791 Accuracy 0.3585\n",
      "Epoch 56 Batch 100 Loss 0.4191 Accuracy 0.3541\n",
      "Epoch 56 Loss 0.4346 Accuracy 0.3524\n",
      "Epoch 57 Batch 0 Loss 0.3859 Accuracy 0.3565\n",
      "Epoch 57 Batch 50 Loss 0.3716 Accuracy 0.3588\n",
      "Epoch 57 Batch 100 Loss 0.4110 Accuracy 0.3545\n",
      "Epoch 57 Loss 0.4286 Accuracy 0.3534\n",
      "Epoch 58 Batch 0 Loss 0.2914 Accuracy 0.3622\n",
      "Epoch 58 Batch 50 Loss 0.3688 Accuracy 0.3582\n",
      "Epoch 58 Batch 100 Loss 0.4067 Accuracy 0.3545\n",
      "Epoch 58 Loss 0.4235 Accuracy 0.3530\n",
      "Epoch 59 Batch 0 Loss 0.3431 Accuracy 0.3636\n",
      "Epoch 59 Batch 50 Loss 0.3606 Accuracy 0.3588\n",
      "Epoch 59 Batch 100 Loss 0.3998 Accuracy 0.3555\n",
      "Epoch 59 Loss 0.4140 Accuracy 0.3545\n",
      "Epoch 60 Batch 0 Loss 0.2867 Accuracy 0.3636\n",
      "Epoch 60 Batch 50 Loss 0.3519 Accuracy 0.3627\n",
      "Epoch 60 Batch 100 Loss 0.3953 Accuracy 0.3576\n",
      "Epoch 60 Loss 0.4136 Accuracy 0.3553\n",
      "Epoch 61 Batch 0 Loss 0.3392 Accuracy 0.3651\n",
      "Epoch 61 Batch 50 Loss 0.3563 Accuracy 0.3608\n",
      "Epoch 61 Batch 100 Loss 0.4051 Accuracy 0.3554\n",
      "Epoch 61 Loss 0.4186 Accuracy 0.3543\n",
      "Epoch 62 Batch 0 Loss 0.2809 Accuracy 0.3722\n",
      "Epoch 62 Batch 50 Loss 0.3538 Accuracy 0.3617\n",
      "Epoch 62 Batch 100 Loss 0.3897 Accuracy 0.3571\n",
      "Epoch 62 Loss 0.4063 Accuracy 0.3550\n",
      "Epoch 63 Batch 0 Loss 0.2523 Accuracy 0.3778\n",
      "Epoch 63 Batch 50 Loss 0.3541 Accuracy 0.3598\n",
      "Epoch 63 Batch 100 Loss 0.3894 Accuracy 0.3563\n",
      "Epoch 63 Loss 0.4076 Accuracy 0.3544\n",
      "Epoch 64 Batch 0 Loss 0.2906 Accuracy 0.3636\n",
      "Epoch 64 Batch 50 Loss 0.3440 Accuracy 0.3611\n",
      "Epoch 64 Batch 100 Loss 0.3855 Accuracy 0.3560\n",
      "Epoch 64 Loss 0.4029 Accuracy 0.3542\n",
      "Epoch 65 Batch 0 Loss 0.3575 Accuracy 0.3778\n",
      "Epoch 65 Batch 50 Loss 0.3550 Accuracy 0.3592\n",
      "Epoch 65 Batch 100 Loss 0.3852 Accuracy 0.3562\n",
      "Epoch 65 Loss 0.4008 Accuracy 0.3549\n",
      "Epoch 66 Batch 0 Loss 0.2605 Accuracy 0.3622\n",
      "Epoch 66 Batch 50 Loss 0.3450 Accuracy 0.3622\n",
      "Epoch 66 Batch 100 Loss 0.3785 Accuracy 0.3572\n",
      "Epoch 66 Loss 0.3962 Accuracy 0.3560\n",
      "Epoch 67 Batch 0 Loss 0.2668 Accuracy 0.3707\n",
      "Epoch 67 Batch 50 Loss 0.3441 Accuracy 0.3598\n",
      "Epoch 67 Batch 100 Loss 0.3848 Accuracy 0.3570\n",
      "Epoch 67 Loss 0.4007 Accuracy 0.3550\n",
      "Epoch 68 Batch 0 Loss 0.3156 Accuracy 0.3636\n",
      "Epoch 68 Batch 50 Loss 0.3422 Accuracy 0.3608\n",
      "Epoch 68 Batch 100 Loss 0.3805 Accuracy 0.3572\n",
      "Epoch 68 Loss 0.3963 Accuracy 0.3553\n",
      "Epoch 69 Batch 0 Loss 0.3043 Accuracy 0.3679\n",
      "Epoch 69 Batch 50 Loss 0.3316 Accuracy 0.3626\n",
      "Epoch 69 Batch 100 Loss 0.3689 Accuracy 0.3583\n",
      "Epoch 69 Loss 0.3863 Accuracy 0.3568\n",
      "Epoch 70 Batch 0 Loss 0.2959 Accuracy 0.3580\n",
      "Epoch 70 Batch 50 Loss 0.3337 Accuracy 0.3609\n",
      "Epoch 70 Batch 100 Loss 0.3762 Accuracy 0.3568\n",
      "Epoch 70 Loss 0.3926 Accuracy 0.3552\n",
      "Epoch 71 Batch 0 Loss 0.2944 Accuracy 0.3849\n",
      "Epoch 71 Batch 50 Loss 0.3352 Accuracy 0.3610\n",
      "Epoch 71 Batch 100 Loss 0.3707 Accuracy 0.3576\n",
      "Epoch 71 Loss 0.3854 Accuracy 0.3562\n",
      "Epoch 72 Batch 0 Loss 0.2777 Accuracy 0.3750\n",
      "Epoch 72 Batch 50 Loss 0.3343 Accuracy 0.3619\n",
      "Epoch 72 Batch 100 Loss 0.3699 Accuracy 0.3571\n",
      "Epoch 72 Loss 0.3842 Accuracy 0.3558\n",
      "Epoch 73 Batch 0 Loss 0.2787 Accuracy 0.3750\n",
      "Epoch 73 Batch 50 Loss 0.3151 Accuracy 0.3636\n",
      "Epoch 73 Batch 100 Loss 0.3599 Accuracy 0.3581\n",
      "Epoch 73 Loss 0.3807 Accuracy 0.3558\n",
      "Epoch 74 Batch 0 Loss 0.3059 Accuracy 0.3608\n",
      "Epoch 74 Batch 50 Loss 0.3307 Accuracy 0.3614\n",
      "Epoch 74 Batch 100 Loss 0.3600 Accuracy 0.3581\n",
      "Epoch 74 Loss 0.3791 Accuracy 0.3562\n",
      "Epoch 75 Batch 0 Loss 0.2088 Accuracy 0.3835\n",
      "Epoch 75 Batch 50 Loss 0.3299 Accuracy 0.3623\n",
      "Epoch 75 Batch 100 Loss 0.3686 Accuracy 0.3570\n",
      "Epoch 75 Loss 0.3832 Accuracy 0.3557\n",
      "Epoch 76 Batch 0 Loss 0.4134 Accuracy 0.3366\n",
      "Epoch 76 Batch 50 Loss 0.3261 Accuracy 0.3627\n",
      "Epoch 76 Batch 100 Loss 0.3552 Accuracy 0.3596\n",
      "Epoch 76 Loss 0.3719 Accuracy 0.3574\n",
      "Epoch 77 Batch 0 Loss 0.2951 Accuracy 0.3679\n",
      "Epoch 77 Batch 50 Loss 0.3250 Accuracy 0.3636\n",
      "Epoch 77 Batch 100 Loss 0.3635 Accuracy 0.3585\n",
      "Epoch 77 Loss 0.3756 Accuracy 0.3569\n",
      "Epoch 78 Batch 0 Loss 0.2463 Accuracy 0.3892\n",
      "Epoch 78 Batch 50 Loss 0.3179 Accuracy 0.3618\n",
      "Epoch 78 Batch 100 Loss 0.3536 Accuracy 0.3582\n",
      "Epoch 78 Loss 0.3708 Accuracy 0.3569\n",
      "Epoch 79 Batch 0 Loss 0.2813 Accuracy 0.3722\n",
      "Epoch 79 Batch 50 Loss 0.3155 Accuracy 0.3629\n",
      "Epoch 79 Batch 100 Loss 0.3535 Accuracy 0.3589\n",
      "Epoch 79 Loss 0.3672 Accuracy 0.3576\n",
      "Epoch 80 Batch 0 Loss 0.2809 Accuracy 0.3594\n",
      "Epoch 80 Batch 50 Loss 0.3147 Accuracy 0.3617\n",
      "Epoch 80 Batch 100 Loss 0.3483 Accuracy 0.3597\n",
      "Epoch 80 Loss 0.3648 Accuracy 0.3573\n",
      "Epoch 81 Batch 0 Loss 0.3388 Accuracy 0.3622\n",
      "Epoch 81 Batch 50 Loss 0.3125 Accuracy 0.3640\n",
      "Epoch 81 Batch 100 Loss 0.3513 Accuracy 0.3595\n",
      "Epoch 81 Loss 0.3644 Accuracy 0.3579\n",
      "Epoch 82 Batch 0 Loss 0.3125 Accuracy 0.3565\n",
      "Epoch 82 Batch 50 Loss 0.3211 Accuracy 0.3629\n",
      "Epoch 82 Batch 100 Loss 0.3539 Accuracy 0.3581\n",
      "Epoch 82 Loss 0.3677 Accuracy 0.3568\n",
      "Epoch 83 Batch 0 Loss 0.2329 Accuracy 0.3920\n",
      "Epoch 83 Batch 50 Loss 0.3158 Accuracy 0.3622\n",
      "Epoch 83 Batch 100 Loss 0.3499 Accuracy 0.3588\n",
      "Epoch 83 Loss 0.3611 Accuracy 0.3580\n",
      "Epoch 84 Batch 0 Loss 0.2795 Accuracy 0.3736\n",
      "Epoch 84 Batch 50 Loss 0.3157 Accuracy 0.3629\n",
      "Epoch 84 Batch 100 Loss 0.3467 Accuracy 0.3596\n",
      "Epoch 84 Loss 0.3618 Accuracy 0.3582\n",
      "Epoch 85 Batch 0 Loss 0.2699 Accuracy 0.3707\n",
      "Epoch 85 Batch 50 Loss 0.3091 Accuracy 0.3627\n",
      "Epoch 85 Batch 100 Loss 0.3443 Accuracy 0.3592\n",
      "Epoch 85 Loss 0.3610 Accuracy 0.3569\n",
      "Epoch 86 Batch 0 Loss 0.2574 Accuracy 0.3679\n",
      "Epoch 86 Batch 50 Loss 0.3005 Accuracy 0.3632\n",
      "Epoch 86 Batch 100 Loss 0.3417 Accuracy 0.3604\n",
      "Epoch 86 Loss 0.3554 Accuracy 0.3585\n",
      "Epoch 87 Batch 0 Loss 0.2830 Accuracy 0.3736\n",
      "Epoch 87 Batch 50 Loss 0.3216 Accuracy 0.3608\n",
      "Epoch 87 Batch 100 Loss 0.3482 Accuracy 0.3591\n",
      "Epoch 87 Loss 0.3596 Accuracy 0.3576\n",
      "Epoch 88 Batch 0 Loss 0.2938 Accuracy 0.3608\n",
      "Epoch 88 Batch 50 Loss 0.3072 Accuracy 0.3640\n",
      "Epoch 88 Batch 100 Loss 0.3366 Accuracy 0.3599\n",
      "Epoch 88 Loss 0.3534 Accuracy 0.3582\n",
      "Epoch 89 Batch 0 Loss 0.3012 Accuracy 0.3651\n",
      "Epoch 89 Batch 50 Loss 0.3054 Accuracy 0.3646\n",
      "Epoch 89 Batch 100 Loss 0.3388 Accuracy 0.3603\n",
      "Epoch 89 Loss 0.3520 Accuracy 0.3587\n",
      "Epoch 90 Batch 0 Loss 0.2930 Accuracy 0.3494\n",
      "Epoch 90 Batch 50 Loss 0.3077 Accuracy 0.3626\n",
      "Epoch 90 Batch 100 Loss 0.3373 Accuracy 0.3597\n",
      "Epoch 90 Loss 0.3516 Accuracy 0.3582\n",
      "Epoch 91 Batch 0 Loss 0.2897 Accuracy 0.3707\n",
      "Epoch 91 Batch 50 Loss 0.2970 Accuracy 0.3637\n",
      "Epoch 91 Batch 100 Loss 0.3331 Accuracy 0.3598\n",
      "Epoch 91 Loss 0.3500 Accuracy 0.3578\n",
      "Epoch 92 Batch 0 Loss 0.2456 Accuracy 0.3722\n",
      "Epoch 92 Batch 50 Loss 0.3022 Accuracy 0.3658\n",
      "Epoch 92 Batch 100 Loss 0.3324 Accuracy 0.3605\n",
      "Epoch 92 Loss 0.3481 Accuracy 0.3583\n",
      "Epoch 93 Batch 0 Loss 0.2778 Accuracy 0.3722\n",
      "Epoch 93 Batch 50 Loss 0.3020 Accuracy 0.3647\n",
      "Epoch 93 Batch 100 Loss 0.3358 Accuracy 0.3602\n",
      "Epoch 93 Loss 0.3476 Accuracy 0.3586\n",
      "Epoch 94 Batch 0 Loss 0.2104 Accuracy 0.3864\n",
      "Epoch 94 Batch 50 Loss 0.2863 Accuracy 0.3663\n",
      "Epoch 94 Batch 100 Loss 0.3326 Accuracy 0.3592\n",
      "Epoch 94 Loss 0.3456 Accuracy 0.3580\n",
      "Epoch 95 Batch 0 Loss 0.2933 Accuracy 0.3778\n",
      "Epoch 95 Batch 50 Loss 0.3008 Accuracy 0.3668\n",
      "Epoch 95 Batch 100 Loss 0.3293 Accuracy 0.3614\n",
      "Epoch 95 Loss 0.3415 Accuracy 0.3590\n",
      "Epoch 96 Batch 0 Loss 0.2454 Accuracy 0.3977\n",
      "Epoch 96 Batch 50 Loss 0.2969 Accuracy 0.3655\n",
      "Epoch 96 Batch 100 Loss 0.3291 Accuracy 0.3613\n",
      "Epoch 96 Loss 0.3450 Accuracy 0.3591\n",
      "Epoch 97 Batch 0 Loss 0.1640 Accuracy 0.3920\n",
      "Epoch 97 Batch 50 Loss 0.2934 Accuracy 0.3639\n",
      "Epoch 97 Batch 100 Loss 0.3241 Accuracy 0.3607\n",
      "Epoch 97 Loss 0.3392 Accuracy 0.3586\n",
      "Epoch 98 Batch 0 Loss 0.2402 Accuracy 0.3707\n",
      "Epoch 98 Batch 50 Loss 0.2877 Accuracy 0.3663\n",
      "Epoch 98 Batch 100 Loss 0.3262 Accuracy 0.3597\n",
      "Epoch 98 Loss 0.3403 Accuracy 0.3586\n",
      "Epoch 99 Batch 0 Loss 0.2981 Accuracy 0.3636\n",
      "Epoch 99 Batch 50 Loss 0.2890 Accuracy 0.3659\n",
      "Epoch 99 Batch 100 Loss 0.3278 Accuracy 0.3604\n",
      "Epoch 99 Loss 0.3408 Accuracy 0.3592\n",
      "Epoch 100 Batch 0 Loss 0.2075 Accuracy 0.3665\n",
      "Epoch 100 Batch 50 Loss 0.2909 Accuracy 0.3645\n",
      "Epoch 100 Batch 100 Loss 0.3236 Accuracy 0.3601\n",
      "Epoch 100 Loss 0.3380 Accuracy 0.3587\n"
     ]
    }
   ],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  \n",
    "  # add extra dimensions to add the padding\n",
    "  # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "  \n",
    "    for (batch, (inp, tar)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        train_step(inp, tar)\n",
    "        if batch % 50 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "              epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "    \n",
    "    print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "LjTSXdnrci3O",
    "outputId": "93065709-4321-4026-aab0-02e1f1a3048f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: good morning.\n",
      "Predicted translation: ['<start>', 'с', 'добрым', 'утром', '!']\n"
     ]
    }
   ],
   "source": [
    "def evaluate(inp_sentence):\n",
    "    start_token = [1]\n",
    "    end_token = [2]\n",
    "  \n",
    "    sentence = preprocess_sentence(inp_sentence)\n",
    "    inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    \n",
    "    encoder_input = tf.expand_dims(inputs, 0)\n",
    "  \n",
    "  # as the target is english, the first word to the transformer should be the\n",
    "  # english start token.\n",
    "    decoder_input = [1]\n",
    "    output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "    for i in range(max_length_targ):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "            encoder_input, output)\n",
    "  \n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        predictions, attention_weights = transformer(encoder_input, \n",
    "                                                 output,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 combined_mask,\n",
    "                                                 dec_padding_mask)\n",
    "    \n",
    "    # select the last word from the seq_len dimension\n",
    "        predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "    # return the result if the predicted_id is equal to the end token\n",
    "        if predicted_id == targ_lang_tokenizer.word_index[\"<end>\"]:\n",
    "            return tf.squeeze(output, axis=0), attention_weights\n",
    "    \n",
    "    # concatentate the predicted_id to the output which is given to the decoder\n",
    "    # as its input.\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0), attention_weights\n",
    "\n",
    "\n",
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "  \n",
    "    sentence = inp_lang_tokenizer.encode(sentence)\n",
    "  \n",
    "    attention = tf.squeeze(attention[layer], axis=0)\n",
    "  \n",
    "    for head in range(attention.shape[0]):\n",
    "        ax = fig.add_subplot(2, 4, head+1)\n",
    "\n",
    "        # plot the attention weights\n",
    "        ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "        fontdict = {'fontsize': 10}\n",
    "\n",
    "        ax.set_xticks(range(len(sentence)+2))\n",
    "        ax.set_yticks(range(len(result)))\n",
    "\n",
    "        ax.set_ylim(len(result)-1.5, -0.5)\n",
    "\n",
    "        ax.set_xticklabels(\n",
    "            ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n",
    "            fontdict=fontdict, rotation=90)\n",
    "\n",
    "        ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
    "                            if i < tokenizer_en.vocab_size], \n",
    "                           fontdict=fontdict)\n",
    "\n",
    "        ax.set_xlabel('Head {}'.format(head+1))\n",
    "  \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def translate(sentence, plot=''):\n",
    "    result, attention_weights = evaluate(sentence)\n",
    "    predicted_sentence = ([targ_lang_tokenizer.index_word[i] for i in result.numpy()])  \n",
    "\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Predicted translation: {}'.format(predicted_sentence))\n",
    "  \n",
    "    if plot:\n",
    "        plot_attention_weights(attention_weights, sentence, result, plot)\n",
    "        \n",
    "translate(\"good morning.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Untitled3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
